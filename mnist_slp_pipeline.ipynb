{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Single Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Development Environment\n",
    "<br/>Single Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Development Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import gzip\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Single Layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_images(file_path, normalize=True):\n",
    "  with gzip.open(file_path,'rb') as f:\n",
    "    features = np.frombuffer(f.read(), dtype=np.uint8, offset=16)\n",
    "    features =  features.reshape(-1, 784)\n",
    "\n",
    "  if normalize:\n",
    "    features = features.astype(np.float32)\n",
    "    features = features / 255.0\n",
    "\n",
    "  return features\n",
    "\n",
    "def read_labels(file_path):\n",
    "  with gzip.open(file_path, 'rb') as f:\n",
    "    labels = np.frombuffer(f.read(), dtype=np.uint8, offset=8)\n",
    "\n",
    "  return labels\n",
    "\n",
    "def data_preprocessor(mnist_dir_path='./'):\n",
    "  train_images_path = os.path.join(mnist_dir_path + 'train-images-idx3-ubyte.gz') \n",
    "  train_labels_path = os.path.join(mnist_dir_path + 'train-labels-idx1-ubyte.gz')\n",
    "  test_images_path = os.path.join(mnist_dir_path + 't10k-images-idx3-ubyte.gz')\n",
    "  test_labels_path = os.path.join(mnist_dir_path + 't10k-labels-idx1-ubyte.gz')\n",
    "\n",
    "  train_images = read_images(train_images_path)\n",
    "  train_labels = read_labels(train_labels_path)\n",
    "  test_images = read_images(test_images_path)\n",
    "  test_labels = read_labels(test_labels_path)\n",
    "\n",
    "  return train_images, train_labels, test_images, test_labels\n",
    "\n",
    "def show_image(image, label):\n",
    "  plt.title(\"Label : {}\".format(str(label)))\n",
    "  plt.imshow(image.reshape(28, 28), cmap=plt.cm.gray_r)\n",
    "  plt.show()\n",
    "\n",
    "def one_hot_encoding(labels):\n",
    "    one_hot_labels = np.zeros((labels.size, 10))\n",
    "    for i in range(labels.size):\n",
    "        one_hot_labels[i, labels[i]] = 1.0\n",
    "    return one_hot_labels\n",
    "\n",
    "def data_loader(train_images, train_labels, test_images, test_labels):\n",
    "       \n",
    "  split = len(test_images) # train:valid:test = 5:1:1\n",
    "  valid_images, valid_labels = train_images[-split:], train_labels[-split:]\n",
    "  train_images, train_labels = train_images[:-split], train_labels[:-split]\n",
    "  \n",
    "  train_labels = one_hot_encoding(train_labels)\n",
    "  valid_labels = one_hot_encoding(valid_labels)\n",
    "  test_labels = one_hot_encoding(test_labels)\n",
    "\n",
    "  train_dataloader = [[i, j] for i, j in zip(train_images, train_labels)]\n",
    "  valid_dataloader = [[i, j] for i, j in zip(valid_images, valid_labels)]\n",
    "  test_dataloader = [[i, j] for i, j in zip(test_images, test_labels)]\n",
    "\n",
    "  return train_dataloader, valid_dataloader, test_dataloader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self, input_size, ouput_size):\n",
    "        self.w = 0.2 * np.random.rand(input_size, ouput_size) - 0.1\n",
    "        self.b = np.zeros(ouput_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.x = x\n",
    "        output = np.dot(x, self.w) + self.b\n",
    "        output = softmax(output)\n",
    "        return output\n",
    "\n",
    "    def backward(self, output, label, learning_rate):\n",
    "        delta = output - label\n",
    "        self.w -= learning_rate * np.outer(self.x, delta)\n",
    "        self.b -= learning_rate * delta\n",
    "\n",
    "def mean_squared_error(y, t):\n",
    "    return 0.5 * np.sum((y - t)**2)\n",
    "\n",
    "def softmax(y):\n",
    "    c = np.max(y)\n",
    "    exp_a = np.exp(y - c)\n",
    "    sum_exp_a = np.sum(exp_a)\n",
    "    y = exp_a / sum_exp_a\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataloader, valid_dataloader):\n",
    "    \n",
    "    learning_rate = 0.1; epochs = 10; \n",
    "    early_stop = \"pass\";  # option: 'pass', 'stop'\n",
    "    overfitting = \"ignore\" # option: 'check', 'ignore'\n",
    "    best_valid_loss = -1\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        \n",
    "        if early_stop == \"pass\":\n",
    "          print(\"Epoch {}\".format(epoch+1))\n",
    "\n",
    "          training_loss = []\n",
    "          for batch in tqdm(train_dataloader):\n",
    "              image = batch[0]; label = batch[1]\n",
    "              output = model.forward(image) \n",
    "              loss = mean_squared_error(output, label)\n",
    "              training_loss.append(loss)\n",
    "              model.backward(output, label, learning_rate)\n",
    "          print(\"Training Loss : {}\".format(np.mean(training_loss)))\n",
    "\n",
    "          valid_loss = []; count = 0\n",
    "          for batch in tqdm(valid_dataloader):\n",
    "              image = batch[0]; label = batch[1]\n",
    "              output = model.forward(image) \n",
    "              loss = mean_squared_error(output, label)\n",
    "              valid_loss.append(loss)\n",
    "              prediction = np.max(output)\n",
    "              gold_label = np.max(label)\n",
    "              if prediction == gold_label: count += 1\n",
    "\n",
    "          accuarcy = count / len(label)\n",
    "          epoch_valid_loss = np.mean(valid_loss)\n",
    "          print(\"Validation Loss : {}\".format(epoch_valid_loss))\n",
    "          print(\"Validation Accuracy : {}\\n\".format(accuarcy))\n",
    "          \n",
    "          if overfitting == \"check\":\n",
    "            if epoch == 0:\n",
    "               best_valid_loss = epoch_valid_loss\n",
    "               best_model = model\n",
    "            elif epoch != 0: \n",
    "              if best_valid_loss >= epoch_valid_loss: \n",
    "                 best_valid_loss = epoch_valid_loss; best_model = model\n",
    "                 early_stop = \"pass\"  \n",
    "              elif best_valid_loss < epoch_valid_loss: early_stop = \"stop\" \n",
    "          elif overfitting == \"ignore\":\n",
    "             best_model = model\n",
    "        \n",
    "        if early_stop == \"stop\":\n",
    "           pass\n",
    "             \n",
    "    return best_model\n",
    "\n",
    "def test(model, test_dataloader):\n",
    "  print(\"Model Evaulation\")\n",
    "  count = 0\n",
    "  for batch in tqdm(test_dataloader):\n",
    "      image = batch[0]; label = batch[1]\n",
    "      output = model.forward(image)\n",
    "\n",
    "      prediction = np.argmax(output)\n",
    "      gold_label = np.max(label)\n",
    "\n",
    "      if prediction == gold_label:\n",
    "        count += 1\n",
    "\n",
    "  accuracy = count / len(test_images)\n",
    "  print(\"Test Accuracy : {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:03<00:00, 14148.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.1165832754465587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 28011.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.09248985452233323\n",
      "Validation Accuracy : 46.5\n",
      "\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:03<00:00, 14072.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.10105227211461607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 26879.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.09635369227756521\n",
      "Validation Accuracy : 45.0\n",
      "\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:03<00:00, 12906.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.09730983195305916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 27395.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.08833496219000342\n",
      "Validation Accuracy : 62.9\n",
      "\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:03<00:00, 13758.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.09505149103804726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 24814.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.09541733784147548\n",
      "Validation Accuracy : 57.4\n",
      "\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:03<00:00, 14005.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.09310320273141512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 16556.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.10081970990437641\n",
      "Validation Accuracy : 56.7\n",
      "\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:03<00:00, 12502.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.09255142936070158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 22124.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.09337401259952909\n",
      "Validation Accuracy : 56.7\n",
      "\n",
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:04<00:00, 12121.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.09159738671573886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 26809.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.09776932437034798\n",
      "Validation Accuracy : 64.7\n",
      "\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:03<00:00, 13207.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.09051283493802671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 25641.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.09777693368728332\n",
      "Validation Accuracy : 63.7\n",
      "\n",
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:03<00:00, 12651.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.0900745618607145\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 26593.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.09335346434583969\n",
      "Validation Accuracy : 73.4\n",
      "\n",
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:04<00:00, 11924.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss : 0.08887131139153087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 22573.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss : 0.09343213453170494\n",
      "Validation Accuracy : 67.8\n",
      "\n",
      "Model Evaulation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:00<00:00, 29326.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy : 0.1202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "\n",
    "  mnist_dir_path = './'\n",
    "  train_images, train_labels, test_images, test_labels = data_preprocessor(mnist_dir_path)\n",
    "  train_dataloader, valid_dataloader, test_dataloader = data_loader(train_images, train_labels, \n",
    "                                                                    test_images, test_labels)\n",
    "  show_image(train_images[0], train_labels[0])\n",
    "  \n",
    "  model = NeuralNetwork(784, 10)\n",
    "  model = train(model, train_dataloader, valid_dataloader)\n",
    "  result = test(model, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Data</b>\n",
    "<br>[MNIST (Original)](http://yann.lecun.com/exdb/mnist/)\n",
    "<br>[MNIST (Hugginface)](https://huggingface.co/datasets/ylecun/mnist)\n",
    "\n",
    "<br><b>Source Code</b>\n",
    "<br>[Google Colab](https://colab.research.google.com/drive/13GedG2V1iAFzDfotNF5xeuA3SXqlJK2s)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "exercise",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
